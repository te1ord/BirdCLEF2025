{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"sourceType":"competition"},{"sourceId":11406881,"sourceType":"datasetVersion","datasetId":7145286},{"sourceId":11471770,"sourceType":"datasetVersion","datasetId":7189316},{"sourceId":11473515,"sourceType":"datasetVersion","datasetId":7190609},{"sourceId":11486003,"sourceType":"datasetVersion","datasetId":7150925}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Env setup","metadata":{}},{"cell_type":"code","source":"# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# secret_value_0 = user_secrets.get_secret(\"Github\")\n# secret_value_1 = user_secrets.get_secret(\"wandb_key\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:08.545101Z","iopub.execute_input":"2025-04-19T15:25:08.545397Z","iopub.status.idle":"2025-04-19T15:25:08.566146Z","shell.execute_reply.started":"2025-04-19T15:25:08.545376Z","shell.execute_reply":"2025-04-19T15:25:08.565266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import wandb\n# wandb.login(key=secret_value_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:08.567681Z","iopub.execute_input":"2025-04-19T15:25:08.568013Z","iopub.status.idle":"2025-04-19T15:25:08.572132Z","shell.execute_reply.started":"2025-04-19T15:25:08.567981Z","shell.execute_reply":"2025-04-19T15:25:08.571264Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# From kagle dataaset","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/birdclef2025-code/main_folder/')\nsys.path.append('/kaggle/input/birdclef2025-env/kaggle_env/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:08.573793Z","iopub.execute_input":"2025-04-19T15:25:08.574271Z","iopub.status.idle":"2025-04-19T15:25:08.594081Z","shell.execute_reply.started":"2025-04-19T15:25:08.574240Z","shell.execute_reply":"2025-04-19T15:25:08.593131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test\nfrom src.datasets.audio_dataset import AudioDataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:08.595658Z","iopub.execute_input":"2025-04-19T15:25:08.595995Z","iopub.status.idle":"2025-04-19T15:25:16.195800Z","shell.execute_reply.started":"2025-04-19T15:25:08.595964Z","shell.execute_reply":"2025-04-19T15:25:16.194957Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Config manager","metadata":{}},{"cell_type":"code","source":"# # copy config to working\n# import shutil\n# shutil.copytree(\"/kaggle/input/birdclef2025-code/main_folder/src/config\", \"/kaggle/working/config\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:16.196737Z","iopub.execute_input":"2025-04-19T15:25:16.197186Z","iopub.status.idle":"2025-04-19T15:25:16.201663Z","shell.execute_reply.started":"2025-04-19T15:25:16.197157Z","shell.execute_reply":"2025-04-19T15:25:16.200726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from omegaconf import OmegaConf\n\n# cfg = OmegaConf.load(\"/kaggle/working/config/config.yaml\") \n# print(OmegaConf.to_container(cfg, resolve=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:16.203624Z","iopub.execute_input":"2025-04-19T15:25:16.203955Z","iopub.status.idle":"2025-04-19T15:25:16.219712Z","shell.execute_reply.started":"2025-04-19T15:25:16.203928Z","shell.execute_reply":"2025-04-19T15:25:16.218800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from hydra import initialize, compose\nfrom omegaconf import OmegaConf\n## \"../input/birdclef2025-code/main_folder/src/config\" - if from input\n\n# if from workign after copy\nwith initialize(config_path=\"../input/birdclef2025-code/main_folder/src/config\"): \n    cfg = compose(config_name=\"config\")  # Load main config.yaml\n\n# print(OmegaConf.to_container(cfg, resolve=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:16.220597Z","iopub.execute_input":"2025-04-19T15:25:16.221145Z","iopub.status.idle":"2025-04-19T15:25:17.017797Z","shell.execute_reply.started":"2025-04-19T15:25:16.221119Z","shell.execute_reply":"2025-04-19T15:25:17.016783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cfg['inference']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:17.018660Z","iopub.execute_input":"2025-04-19T15:25:17.018978Z","iopub.status.idle":"2025-04-19T15:25:17.029052Z","shell.execute_reply.started":"2025-04-19T15:25:17.018953Z","shell.execute_reply":"2025-04-19T15:25:17.028114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# paths\ncfg['data'][\"paths\"]['train_csv'] = \"/kaggle/input/birdclef2025-cv-split/cv_split.csv\"\ncfg['inference']['train_audio_path'] = \"/kaggle/input/birdclef-2025/train_audio\"\ncfg['inference']['test_soundscape_path'] =\"/kaggle/input/birdclef-2025/test_soundscapes\"\ncfg['inference']['checkpoint_path'] = \"/kaggle/input/birdclef2025-models/efficientnet_b0__weights_power-0.5-1st.ckpt\"\ncfg['inference']['batch_size'] = 2048","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:17.030039Z","iopub.execute_input":"2025-04-19T15:25:17.030402Z","iopub.status.idle":"2025-04-19T15:25:17.049266Z","shell.execute_reply.started":"2025-04-19T15:25:17.030370Z","shell.execute_reply":"2025-04-19T15:25:17.048403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # test on train soundscapes\n# cfg['inference']['test_soundscape_path'] =\"/kaggle/input/birdclef-2025/train_soundscapes\"\n# cfg['inference']['test_soundscape_path']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:17.074923Z","iopub.execute_input":"2025-04-19T15:25:17.075318Z","iopub.status.idle":"2025-04-19T15:25:17.092209Z","shell.execute_reply.started":"2025-04-19T15:25:17.075286Z","shell.execute_reply":"2025-04-19T15:25:17.091324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"from src.scripts.inference import main\nmain(cfg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:17.093061Z","iopub.execute_input":"2025-04-19T15:25:17.093370Z","iopub.status.idle":"2025-04-19T15:28:58.468598Z","shell.execute_reply.started":"2025-04-19T15:25:17.093338Z","shell.execute_reply":"2025-04-19T15:28:58.466662Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Debug","metadata":{}},{"cell_type":"code","source":"# import os\n# import torch\n# import librosa\n# import numpy as np\n# import pandas as pd\n# from typing import List, Optional, Tuple\n# from pathlib import Path\n# from tqdm import tqdm\n# from itertools import chain\n\n# from src.models.spec_cnn import SpecCNNClassifier\n\n\n# class Inference:\n#     def __init__(\n#         self,\n#         model_path: str,\n#         class_labels: List[str],\n#         sample_rate: int = 32000,\n#         target_duration: float = 5.0,\n#         device: str = \"cuda\",\n#         batch_size: int = 128,\n#         model_config: Optional[dict] = None,\n#     ):\n#         self.model_path = model_path\n#         self.class_labels = class_labels\n#         self.sample_rate = sample_rate\n#         self.target_duration = target_duration\n#         self.device = device\n#         self.batch_size = batch_size\n#         self.model_config = model_config or {}\n        \n#         self.model = self._load_model()\n#         self.model.eval()\n\n#         self.logger = []\n        \n#     def _load_model(self) -> SpecCNNClassifier:\n#         \"\"\"Load the trained model from checkpoint.\"\"\"\n#         checkpoint = torch.load(self.model_path, map_location=self.device)\n        \n#         self.model_config['pretrained'] = False\n#         model = SpecCNNClassifier(\n#             **self.model_config,\n#             device=self.device\n#         )\n        \n#         if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n#             state_dict = checkpoint['state_dict']\n#             state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n#             model.load_state_dict(state_dict)\n#         else:\n#             model.load_state_dict(checkpoint)\n            \n#         model = model.to(self.device)\n#         return model\n    \n#     def _prepare_audio_chunk(self, audio: np.ndarray) -> torch.Tensor:\n#         \"\"\"Prepare audio chunk for inference.\"\"\"\n#         target_length = int(self.sample_rate * self.target_duration)\n#         if len(audio) < target_length:\n#             audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n#         elif len(audio) > target_length:\n#             start_idx = max(0, int(len(audio) / 2 - target_length / 2))\n#             audio = audio[start_idx:start_idx + target_length]\n            \n#         audio = torch.from_numpy(audio).float()\n#         return audio\n    \n#     def _get_audio_chunks(self, audio_path: str):\n#         \"\"\"Get all chunks from an audio file with their metadata.\"\"\"\n#         try:\n#             audio, _ = librosa.load(audio_path, sr=self.sample_rate)\n#             soundscape_id = Path(audio_path).stem\n            \n#             chunk_size = int(self.sample_rate * self.target_duration)\n#             for i in range(0, len(audio), chunk_size):\n#                 chunk = audio[i:i + chunk_size]\n#                 yield (chunk, soundscape_id, i // chunk_size)\n#         except Exception as e:\n#             print(f\"Error processing {audio_path}: {e}\")\n#             return []\n    \n#     def _process_batch(self, batch: List[Tuple[np.ndarray, str, int]]) -> pd.DataFrame:\n#         \"\"\"Process a batch of audio chunks and return predictions.\"\"\"\n#         audio_chunks, soundscape_ids, chunk_indices = zip(*batch)\n\n#         # print(f\"Soundscape ID, Chunk index = {list(zip(soundscape_ids, chunk_indices))}\")\n#         self.logger.append(list(zip(soundscape_ids, chunk_indices)))\n        \n#         batch_tensor = torch.stack([self._prepare_audio_chunk(chunk) for chunk in audio_chunks])\n#         batch_tensor = batch_tensor.to(self.device)\n        \n#         with torch.no_grad():\n#             output = self.model(batch_tensor)\n#             logits = output[\"logits\"]\n#             scores = torch.sigmoid(logits).cpu().numpy()\n        \n#         predictions = pd.DataFrame(columns=['row_id'] + self.class_labels)\n        \n#         for i, (soundscape_id, chunk_idx) in enumerate(zip(soundscape_ids, chunk_indices)):\n#             row_id = f\"{soundscape_id}_{(chunk_idx + 1) * int(self.target_duration)}\"\n#             new_row = pd.DataFrame([[row_id] + list(scores[i])], \n#                                  columns=['row_id'] + self.class_labels)\n#             predictions = pd.concat([predictions, new_row], axis=0, ignore_index=True)\n            \n#         return predictions\n    \n#     def predict_directory(self, directory_path: str) -> pd.DataFrame:\n#         \"\"\"Make predictions for all audio files in a directory.\"\"\"\n#         all_predictions = pd.DataFrame(columns=['row_id'] + self.class_labels)\n        \n#         audio_files = [os.path.join(directory_path, afile) \n#                             for afile in sorted(os.listdir(directory_path)) \n#                             if afile.endswith('.ogg')]\n#         print(audio_files)\n\n#         # test\n#         audio_files = audio_files[:10]\n\n#         batch = []\n        \n#         for audio_file in tqdm(audio_files, desc=\"Loading audio files\"):\n            \n#             for chunk in self._get_audio_chunks(audio_file):\n#                 batch.append(chunk)\n\n#                 if len(batch) == self.batch_size:\n#                     preds = self._process_batch(batch)\n\n#                     all_predictions = pd.concat([all_predictions, preds], \n#                                       axis=0, ignore_index=True)\n#                     batch = []\n        \n#         # finish remaining batches\n#         if batch:\n#             preds = self._process_batch(batch)\n#             all_predictions = pd.concat([all_predictions, preds], \n#                                       axis=0, ignore_index=True)\n        \n#         for i in self.logger:\n#             print(i)\n#             print()\n\n#         return all_predictions ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:28:58.469292Z","iopub.status.idle":"2025-04-19T15:28:58.469593Z","shell.execute_reply.started":"2025-04-19T15:28:58.469457Z","shell.execute_reply":"2025-04-19T15:28:58.469470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import hydra\n# from omegaconf import DictConfig\n# import pandas as pd\n# from pathlib import Path\n\n\n# model_path = Path(cfg.inference.checkpoint_path)\n# test_soundscape_path = Path(cfg.inference.test_soundscape_path)\n\n\n# df = pd.read_csv(cfg.data.paths.train_csv)\n# class_labels = sorted(df.primary_label.unique())\n# #sorted(os.listdir(cfg.data.train_audio_path))\n\n# print(f\"LEN LABELS:{len(class_labels)}\")\n\n# model_config = {\n#     \"backbone\": cfg.model.backbone,\n#     \"n_classes\": cfg.model.n_classes,\n#     \"classifier_dropout\": cfg.model.classifier_dropout,\n#     \"top_db\": cfg.model.top_db,\n#     \"spec_params\": dict(cfg.model.spec_params),\n#     \"normalize_config\": dict(cfg.model.normalize_config),\n#     \"pretrained\": cfg.model.pretrained,\n# }\n\n# inference = Inference(\n#     model_path=str(model_path),\n#     class_labels=class_labels,\n#     sample_rate=cfg.data.dataset_args.train_args.sample_rate,\n#     target_duration=cfg.data.dataset_args.train_args.target_duration,\n#     device=cfg.model.device,\n#     batch_size = 128,\n#     model_config=model_config,\n# )\n\n# predictions = inference.predict_directory(str(test_soundscape_path))\n\n\n# os.makedirs(cfg.output_dir, exist_ok=True)\n# output_path = Path(cfg.output_dir) / \"submission.csv\"\n\n# predictions.to_csv(output_path, index=False)\n# print(f\"Predictions saved to {output_path}\")\n# print(\"\\nFirst few predictions:\")\n# print(predictions.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:28:58.470805Z","iopub.status.idle":"2025-04-19T15:28:58.471185Z","shell.execute_reply.started":"2025-04-19T15:28:58.471040Z","shell.execute_reply":"2025-04-19T15:28:58.471054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}